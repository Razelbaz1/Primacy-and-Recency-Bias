{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e51b46b3-12fc-4dd4-8119-206abba91bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ast\n",
    "from itertools import combinations\n",
    "import matplotlib.pyplot as plt\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062f3007-9aed-41d5-aaf0-fcd391232084",
   "metadata": {},
   "source": [
    "#### Step 1: GitHub API and CSV Files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6dd732f-04a7-4bb7-8301-db053923f05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GitHub API URL\n",
    "url = 'https://api.github.com/repos/Razelbaz1/Primacy-and-Recency-Bias/contents/Data'\n",
    "# Checking access to the site\n",
    "response = requests.get(url)\n",
    "data = response.json()\n",
    "\n",
    "# Creating a list of relevant links\n",
    "csv_files = [file['download_url'] for file in data if file['name'].endswith('.csv')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d53af69c-89a3-4151-aaf0-8584ee79f4fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2975d9d2-c3c4-4400-8e4a-14996bae8e6b",
   "metadata": {},
   "source": [
    "#### Step 2: Define Helper Functions\n",
    "\n",
    "- `parse_list_rank(row)`: Converts the string representation of a list of tuples into an actual list of tuples.\n",
    "- `extract_numeric(group_id)`: Extracts the numeric part from a group ID (e.g., `a3` -> `3`).\n",
    "- `calculate_lag(group1, group2)`: Computes the absolute difference between the numeric parts of two group IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16c4b431-f898-4a3a-8800-edc79ac7810e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to parse list_rank column\n",
    "def parse_list_rank(row):\n",
    "    return ast.literal_eval(row)\n",
    "\n",
    "# Function to extract numeric part from group ID\n",
    "def extract_numeric(group_id):\n",
    "    return int(group_id[1:])\n",
    "\n",
    "# Function to calculate lag values\n",
    "def calculate_lag(group1, group2):\n",
    "    return abs(extract_numeric(group1) - extract_numeric(group2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745410b1-e8ab-40c1-844f-0ccd8ea1592e",
   "metadata": {},
   "source": [
    "#### Step 3: Process Each CSV File\n",
    "\n",
    "Initialize an empty list `all_combined_dfs` to store the processed DataFrames.\n",
    "\n",
    "For each CSV file:\n",
    "1. **Load the CSV File:** Load the CSV file into a DataFrame.\n",
    "2. **Parse the `list_rank` Column:** Convert the string representation of the list of tuples into an actual list of tuples.\n",
    "3. **Extract Participant ID and Rankings:** Iterate through each row of the data, extract the `username` and `parsed_rank` information, and create a list of dictionaries with `username`, `group`, and `score`.\n",
    "4. **Create a DataFrame from the Parsed Data:** Convert the list of dictionaries into a DataFrame `parsed_df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3cac71cc-9f64-4135-80e8-86005015eeac",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_combined_dfs = []\n",
    "\n",
    "# Process each CSV file\n",
    "for session_id, csv_url in enumerate(csv_files, start=1):\n",
    "    # Load the CSV file\n",
    "    data = pd.read_csv(csv_url)\n",
    "    \n",
    "    # Parse the list_rank column\n",
    "    data['parsed_rank'] = data['list_rank'].apply(parse_list_rank)\n",
    "\n",
    "    # Extract participant ID and their rankings\n",
    "    parsed_data = []\n",
    "\n",
    "    for _, row in data.iterrows():\n",
    "        username = row['username']\n",
    "        ranks = row['parsed_rank']\n",
    "        \n",
    "        for group, score in ranks:\n",
    "            parsed_data.append({\n",
    "                'username': username,\n",
    "                'group': group,\n",
    "                'score': score\n",
    "            })\n",
    "\n",
    "    # Create a DataFrame from the parsed data\n",
    "    parsed_df = pd.DataFrame(parsed_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d066033-76b1-4b92-b067-36054e769117",
   "metadata": {},
   "source": [
    "#### Step 4: Calculate Lag Values and Determine Bias\n",
    "\n",
    "Iterate through each `username` and group the data by `score`. For each score group:\n",
    "\n",
    "1. **Get All Combinations of Pairs:** Generate all possible pairs of groups with the same score.\n",
    "2. **Calculate Lag Values:** Calculate the lag values between each pair.\n",
    "3. **Determine Primacy or Recency Bias:** Determine whether the comparison indicates `primacy` or `recency` based on the numeric order of the groups.\n",
    "4. **Append Results:** Append the results to the `lag_data` list.\n",
    "\n",
    "Finally, Create a DataFrame `lag_df` from the `lag_data` list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79f22dab-b8a6-4b71-8e15-0b03d5546a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find pairs with the same score and calculate lag\n",
    "lag_data = []\n",
    "\n",
    "for username, group_df in parsed_df.groupby('username'):\n",
    "    same_score_groups = group_df.groupby('score')\n",
    "        \n",
    "    for score, score_df in same_score_groups:\n",
    "        # Get all combinations of pairs\n",
    "        for row1, row2 in combinations(score_df.itertuples(index=False), 2):\n",
    "            lag_value = calculate_lag(row1.group, row2.group)\n",
    "                \n",
    "            # Determine primacy or recency\n",
    "            if extract_numeric(row1.group) > extract_numeric(row2.group):\n",
    "                bias = 'recency'\n",
    "            else:\n",
    "                bias = 'primacy'\n",
    "                \n",
    "            lag_data.append({\n",
    "                'username': username,\n",
    "                'group1': row1.group,\n",
    "                'group2': row2.group,\n",
    "                'score': score,\n",
    "                'lag': lag_value,\n",
    "                'bias': bias\n",
    "            })\n",
    "\n",
    "# Create a DataFrame for the lag data\n",
    "lag_df = pd.DataFrame(lag_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b9a1db-2d79-4afb-8476-d714eb9e5b58",
   "metadata": {},
   "source": [
    "#### Step 5: Split Bias Column and Add session_id\n",
    "\n",
    "Split the `bias` column into two separate columns, `primacy` and `recency`, and set the values to 1 or 0 accordingly.\n",
    "\n",
    "Create a final DataFrame `final_df` with the relevant columns: \n",
    "\n",
    "`username`, `score`, `lag`, `primacy`, and `recency`. \n",
    "\n",
    "And add a `session_id` column to the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a49f2ca-d369-4e43-a6c4-53d287e39fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the bias column into 'primacy' and 'recency' columns\n",
    "lag_df['primacy'] = lag_df['bias'].apply(lambda x: 1 if x == 'primacy' else 0)\n",
    "lag_df['recency'] = lag_df['bias'].apply(lambda x: 1 if x == 'recency' else 0)\n",
    "\n",
    "# Final table structure\n",
    "final_df = lag_df[['username', 'score', 'lag', 'primacy', 'recency']].copy()\n",
    "final_df.loc[:, 'session_id'] = session_id  # Add the session_id column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230eec9d-e95b-4603-92ba-9207ba0b9780",
   "metadata": {},
   "source": [
    "#### Step 6: Group and Aggregate Data\n",
    "\n",
    "Group the final DataFrame by `username`, `score`, `lag`, and `session_id`.\n",
    "\n",
    "Aggregate the `primacy` and `recency` columns by summing their values. \n",
    "\n",
    "Then, reset the index of the resulting DataFrame and append it to the `all_combined_dfs` list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0c22c0a-b3fd-42b2-95f6-8d818c151cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'username', 'score', 'lag', and 'session_id' and aggregate 'primacy' and 'recency' columns\n",
    "combined_df = final_df.groupby(['username', 'score', 'lag', 'session_id']).agg({\n",
    "    'primacy': 'sum',\n",
    "    'recency': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "all_combined_dfs.append(combined_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e758ed73-2f2c-4807-9175-e4befd317e17",
   "metadata": {},
   "source": [
    "#### Step 7: Concatenate All Combined DataFrames\n",
    "\n",
    "Concatenate all DataFrames stored in the `all_combined_dfs` list into a single DataFrame `final_combined_df`,\n",
    "ignoring the index. Finally, we display the first few rows of the final combined DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14cf3b7b-2bef-4b65-bea7-ffdecfca0f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate all combined DataFrames\n",
    "final_combined_df = pd.concat(all_combined_dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "236c3a9a-6b8f-4597-b607-db6666c02782",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(298, 6)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_combined_df.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
